\section{Các khảo sát liên quan đến đề tài}

Trong chương này, sẽ trình bày khảo sát về bài toán Nhận diện hành động trong video. Bao gồm: tính ứng dụng và các thách thức của bài toán, các phương pháp truyền thống, các phương pháp học sâu và cuối cùng là phương pháp mới xuất hiện trong hai năm trở lại đây và đạt được các kết quả đáng ngạc nhiên, graph convolutional network (GCN).

\subsection{Khảo sát chung}
Nhận diện hành động (action recognition) của con người có thể được chia thành hai bước là Phát hiện hành động (action detection) và Phân loại hành động (action classification).

\begin{itemize}
    \item Phân loại hành động là quá trình xác định hành động trong đoạn video được cắt ngắn và chỉ chứa duy nhất một hành động cần được phân loại. Đây là bước được các nhà nghiên cứu quan tâm từ rất sớm và đã có nhiều thành tự nhất định. % bắt buộc cite chỗ này
    \item Phát hiện hành động là quá trình tìm ra khoảng thời gian bắt đầu và thời gian kết thúc của hành động trong một video dài chứa nhiều hành động. Đây là bước quan trọng để ứng dụng vào thực tế, tuy nhiên vẫn chưa được quan tâm nhiều, và vẫn còn là thách thức lớn cần giải quyết.
\end{itemize}

Các kỹ thuật nhận diện hành động ngày nay có thể được chia làm 4 loại dựa trên tính chất hành động:

\begin{itemize} % cho vài nhận xét
    \item Nhận diện các hành động cơ bản của một bộ phận trên cơ thể như vẫy tay, nhấc chân, uốn cong người...
    \item Nhận diện hành động của nhiều bộ phận phối hợp nhau trên một cơ thể như đi bộ, nhảy xa, đấm.
    \item Nhận diện hành động có sự tương tác giữa người và một đối tượng khác như đánh đàn, cầm dao....
    \item Nhận diện hành động của một nhóm người như biểu tình, họp nhóm ...
\end{itemize}

\subsection{Khảo sát tính ứng dụng}

Nhận diện hành động của con người có tính ứng dụng cao, và nhận được sự quan tâm mạnh mẽ của cộng đồng, có thể kể đến các công trình nghiên cứu như:

\begin{itemize}
    \item Hệ thống giám sát và nhận diện bất thường trong môi trường nhà ở. Bài báo \cite{gunale2019intelligent} đã trình bày phương pháp đơn giản sử dụng MHI để trích suất suất đặc trưng thủ công và sử dụng SVM để phân loại từ đó phát hiện hành động té ngã. Đây là ứng dụng thiết thực đối với người già thường ở nhà một mình.
    \item Hệ thống tìm kiếm, truy vấn video theo hành động. David Doermann và Daniel DeMenthon đã đề suất phương pháp chia video giám sát thành các video ngắn có độ dài nữa giây, từ đó gán nhãn lưu trữ dưới cấu dữ liệu dạng cây để phục vụ truy vấn \cite{lin2012human}. Ví dụ cho về tính ứng dụng cho hệ thống có thể giúp ta phát ăn cắp tại các văn phòng.
    \item Hệ thống phát hiện lỗi của vận động viên cho các cuộc thi thể thao. Điển hình của ứng dụng này là hệ thống VAR của FIFA đã ứng dụng năm 2018 để  hỗ trợ trọng tài đưa ra quyết định về lỗi \cite{petersen2019var}.
\end{itemize}

Có thể thấy bài toán nhận diện hành động trong video mang lại nhiều tính ứng dụng thực tiễn trong đời sống, vì vậy nhóm mong muốn tìm hiểu về bài toán này.

\subsection{Khảo sát các thách thức}

\subsection{Khảo sát tập dữ liệu}

\subsection{Khảo sát các phương pháp truyền thống}

\subsubsection{Phương pháp biểu diễn dữ liệu toàn cục}

Đây là phương pháp dựa vào các tính chất toàn cục về mặt thời gian và không gian của toàn bộ khung nhìn để trích suất vector đặc trưng từ dữ liệu. Phương pháp này mã hóa được các kiến thức về mặt không gian như các tư thế, các chuyển động theo thời gian. Và đây là các đặc trưng mạnh mẽ để nhận diện hành động.

Hai giải thuật đại diện cho phương pháp này là Motion History Image (MHI) và Motion Energy Image (MEI). Cả hai phương pháp đều trích xuất hành động trong video thành 1 ảnh tỉnh duy nhất.

\begin{itemize}
    \item MEI tạo ra một mặt nạ chuyển động (motion mask). Tại các vùng có chuyển động xảy ra, mặt nạ có giá trị 1 và ngược lại là giá trị 0. Từ đó, sự phân bố không gian của chuyển động được biểu diễn và vùng sáng cho thấy nơi cả hành động xảy ra.
    \item MHI tương tự như MEI, nhưng ngoài cho thấy được hành động diễn ra ở đâu thì MHI còn cho biết nó diễn ra như thế nào về mặt thời gian. Cường độ của mỗi pixel trên MHI thể hiện lịch sử chuyển động tại vị trí đó, trong đó các giá trị sáng hơn tương ứng với chuyển động gần đây hơn.
\end{itemize}

Khả năng trích suất đặc trưng của hai giải thuật trên là rất ấn tượng khi trích suất trên tập dữ liệu có góc nhìn cố định, và chỉ có chủ thể cần nhận diện hành động là di chuyển. Hai điều kiện trên rất khó xảy ra trong thức tế, vì vậy cần những phương pháp khác phù hợp hơn.

% TODO: 3DHOG 

\subsubsection{Phương pháp biểu diễn dữ liệu cục bộ}

Để khắc phục yếu điểm của phương pháp trích suất toàn cục, các phương pháp trích suất cục bộ đã ra đời, và hai đại diện nổi trội nhất cho phương pháp này là space-time interest points (STIP) và motion trajectory (MT).

Các phương pháp dựa trên STIP không chỉ trích xuất các đặc trưng về không gian mà còn có thêm thời gian. Nhờ đó phương pháp này được sử dụng rộng rãi trong bài toán nhận diện hành động. Nó cho phép trích xuất được những chuyển động quan trọng từ video để biểu diện hành động. Hầu hết các phương pháp dựa trên STIP đều kế thừa từ các phương pháp phát hiện vật thể cổ điển dùng cho ảnh tĩnh. Phổ biến nhất có thể kể đến giải thuật 3D-Harris, KLT, SIFT, HOG-HOF-MBH, PCA.

% Khó quá , Thức cứu Khôi nha <3









\subsection{Khảo sát các phương pháp học sâu}

Trong những năm gần đây, việc ứng dụng học sâu vào thị giác máy tính đã nhận được nhiều sự quan tâm đáng kể. Nhiều phương pháp biểu diễn hành động dựa trên học sâu đã được đề xuất trong bài toán Nhận diện hành động trong video.

Các mô hình học sâu đó chủ yếu giải quyết đặc tính đặc biệt của dữ liệu đó dữ liệu dạng chuỗi các ảnh tĩnh. Và trong đó, các mô hình chủ yếu dựa trên 3 mô hình sau:


\textbf{3D convolutional networks:} mô hình này là sử mở rộng của 2D ConvNets vì chúng thu thêm thông tin về thời gian. Đây là một trong những phương pháp đầu tiên ứng dụng CNN để nhận diện hành động. Tuy nhiên phương pháp này tốn chi phí tính toán lớn, vì phải thực hiện 3D convolution trên nhiều frame liền kề nhau để trích suất cả thông tin về không gian và thời gian. Giải thuật này có hạn chế  rõ ràng là chúng thường xét các khoảng thời gian rất ngắn, thường khoảng 16 hay 32 khung hình để giảm chi phí tính toán.

\textbf{Two-stream convolutional networks:} Giống như tên gọi, đầu vào của mô hình gồm 2 thành phầm. Một là ảnh tĩnh chứa thông tin về không gian. Hai là optical flow được tính từ chuỗi các frame hình, chứa thông tin về thời gian. Hai đầu vào sẽ được đưa vào hai mạng CNN nhằm trích suất kiến thức về không thời gian. Kết quả của hai nhánh sẽ được tổng hợp lại để phân loại.

\textbf{Long short-term memory (LSTM):} Một cách tiếp cận khác để trích suất được thông tin về thời gian đó là thêm lớp họ RNN và CNN 2D, chẳng hạn như LSTM. Nhờ đó mô hình này có thể được khả năng hiểu dữ liệu không gian mạnh mẽ của CNN và trí nhớ dài hạn của LSTM.