\section{Các khảo sát liên quan đến đề tài}

Trong chương này, sẽ trình bày khảo sát về bài toán Nhận diện hành động trong video. Bao gồm: tính ứng dụng và các thách thức của bài toán, các phương pháp truyền thống, các phương pháp học sâu và cuối cùng là phương pháp mới xuất hiện trong hai năm trở lại đây và đạt được các kết quả đáng ngạc nhiên, graph convolutional network (GCN).

\subsection{Khảo sát chung}
Nhận diện hành động (action recognition) của con người có thể được chia thành hai bước là Phát hiện hành động (action detection) và Phân loại hành động (action classification).

\begin{itemize}
    \item Phân loại hành động là quá trình xác định hành động trong đoạn video được cắt ngắn và chỉ chứa duy nhất một hành động cần được phân loại. Đây là bước được các nhà nghiên cứu quan tâm từ rất sớm và đã có nhiều thành tự nhất định. % bắt buộc cite chỗ này
    \item Phát hiện hành động là quá trình tìm ra khoảng thời gian bắt đầu và thời gian kết thúc của hành động trong một video dài chứa nhiều hành động. Đây là bước quan trọng để ứng dụng vào thực tế, tuy nhiên vẫn chưa được quan tâm nhiều, và vẫn còn là thách thức lớn cần giải quyết.
\end{itemize}

Các kỹ thuật nhận diện hành động ngày nay có thể được chia làm 4 loại dựa trên tính chất hành động:

\begin{itemize} % cho vài nhận xét
    \item Nhận diện các hành động cơ bản của một bộ phận trên cơ thể như vẫy tay, nhấc chân, uốn cong người...
    \item Nhận diện hành động của nhiều bộ phận phối hợp nhau trên một cơ thể như đi bộ, nhảy xa, đấm.
    \item Nhận diện hành động có sự tương tác giữa người và một đối tượng khác như đánh đàn, cầm dao....
    \item Nhận diện hành động của một nhóm người như biểu tình, họp nhóm ...
\end{itemize}

\subsection{Khảo sát tính ứng dụng}

Nhận diện hành động của con người có tính ứng dụng cao và nhận được sự quan tâm mạnh mẽ của cộng đồng, có thể kể đến các công trình nghiên cứu như:

\begin{itemize}
    \item Hệ thống giám sát và nhận diện bất thường trong môi trường nhà ở. Bài báo \cite{gunale2019intelligent} đã trình bày phương pháp đơn giản sử dụng MHI để trích suất suất đặc trưng thủ công và sử dụng SVM để phân loại từ đó phát hiện hành động té ngã. Đây là ứng dụng thiết thực đối với người già thường ở nhà một mình.
    \item Hệ thống tìm kiếm, truy vấn video theo hành động. David Doermann và Daniel DeMenthon đã đề suất phương pháp chia video giám sát thành các video ngắn có độ dài nữa giây, từ đó gán nhãn lưu trữ dưới cấu dữ liệu dạng cây để phục vụ truy vấn \cite{lin2012human}. Ví dụ cho tính ứng dụng của hệ thống là có thể giúp ta phát hiện ăn cắp tại các văn phòng.
    \item Hệ thống phát hiện lỗi của vận động viên cho các cuộc thi thể thao. Điển hình của ứng dụng này là hệ thống VAR của FIFA đã ứng dụng năm 2018 để  hỗ trợ trọng tài đưa ra quyết định về lỗi \cite{petersen2019var}.
\end{itemize}

Có thể thấy bài toán nhận diện hành động trong video mang lại nhiều tính ứng dụng thực tiễn trong đời sống, vì vậy nhóm quyết định tìm hiểu về bài toán này.

\subsection{Khảo sát các thách thức}

Thách thức đầu tiên phải nói đến dữ liệu. Khác với với tập dữ liệu ảnh tỉnh, chỉ có các chiều dữ liệu không gian, tập dữ liệu cho bài toán này còn mở rộng thêm chiều thời gian. Thách thức đặt ra là ta cần tìm một phương pháp trích suất được tốt kiến thức của cả chiều không gian và thời gian. Đã có nhiều phương pháp được đưa ra, có thể  kể đến các phương pháp thủ công \ref{survey:method-handcraft}, các phương pháp học sâu \ref{survey:method-deep-learning}.

Tuy nhiên các cách trích suất này chưa thực sự tốt cho kiểu dữ liệu skeleton, có dạng dữ liệu đồ thị. Trong tài liệu này nhóm trình bài mô hình graph convolutional network để xây dựng adaptive graph được lấy ý tưởng từ bài báo \cite{shi2020skeleton} và những cải tiến nhóm đề xuất.

\subsection{Khảo sát tập dữ liệu}

Có ba kiểu dữ liệu phổ biến được sử dụng cho bài toán:

\begin{itemize}
    \item Dữ liệu màu (RGB): Tập dữ liệu là một chuỗi các ảnh màu theo hệ màu RGB. Đây là dữ liệu phổ biến được sử dụng nhiều nhất.
    \item Dữ liệu độ sâu (Depth): Tập dữ liệu là một chuỗi các ảnh độ sâu, với các giá trị càng lớn (càng sáng) là càng gần camera, các giá trị càng nhỏ (càng tối) là càng xa camera. Tập dữ liệu này mang lượng kiến thức về tư thế của con người khá tốt, bởi chủ thể luôn đứng gần camera hơn so với nền xung quanh. Tập dữ liệu này cũng được cộng đồng nghiên cứu nhiều và cho kết quả tốt.
    \item Dữ liệu khung xương (skeleton): tập dữ liệu là một chuỗi các đồ thị biểu diễn khung xương của con người, mỗi khung xương chứa tập hợp các khớp (joint) được biểu diễn bằng tọa độ trong không gian 2 hoặc 3 chiều. Tập dữ liệu này gần đây mới được khai thác nhiều nhờ sự xuất hiện của giải thuật graph convolutional network. Nhóm sẽ chủ yế xử lý trên tập này.
\end{itemize}

Khá nhiều tập dữ liệu được công bố công khai cho bài toán nhận diện hành động. Nhóm đã tìm hiểu thông qua bài khảo sát \cite{zhang2019comprehensive} và bảng \ref{table:dataset-popular} được trích lại từ \cite{zhang2019comprehensive}:


Trong các tập dữ liệu được liệt kê, tập dữ liệu có số góc nhìn, số chủ thể, số camera, số class nhiều nhất là tập NTU RGB+D. Tập dữ liệu này có đủ cả 3 loại dữ liệu về RGB, độ sâu và skeleton. Nhóm đã quyết định chọn tập dữ liệu này để thực nghiệm.


\begin{table}[]
    \centering
    \begin{tabular}{|l|c|c|c|l|l|}
        \hline
        Dataset Name       & Color   & Depth   & Skeleton & Samples & Classes \\ \hline
        Hollywood2         & $\surd$ & $X$     & $X$      & 1707    & 12      \\ \hline
        HMDB51             & $\surd$ & $X$     & $X$      & 6766    & 51      \\ \hline
        Olympic Sports     & $\surd$ & $X$     & $X$      & 783     & 16      \\ \hline
        UCF50              & $\surd$ & $X$     & $X$      & 6618    & 50      \\ \hline
        UCF101             & $\surd$ & $X$     & $X$      & 13,320  & 101     \\ \hline
        Kinetics           & $\surd$ & $X$     & $X$      & 306,245 & 400     \\ \hline
        MSR-Action3D       & $X$     & $\surd$ & $\surd$  & 567     & 20      \\ \hline
        MSR-Daily Activity & $\surd$ & $\surd$ & $\surd$  & 320     & 16      \\ \hline
        Northwestern-UCLA  & $\surd$ & $\surd$ & $\surd$  & 1475    & 10      \\ \hline
        UTD-MHAD           & $\surd$ & $\surd$ & $\surd$  & 861     & 27      \\ \hline
        RGBD-HuDaAct       & $\surd$ & $\surd$ & $X$      & 1189    & 13      \\ \hline
        NTU RGB+D          & $\surd$ & $\surd$ & $\surd$  & 56,880  & 60      \\ \hline
    \end{tabular}
    \caption{Các tập dữ liệu phổ biến cho bài toán nhận diện hành động}
    \label{table:dataset-popular}
\end{table}

\subsection{Khảo sát các phương pháp truyền thống}
\label{survey:method-handcraft}

\subsubsection{Phương pháp biểu diễn dữ liệu toàn cục}

Đây là phương pháp dựa vào các tính chất toàn cục về mặt thời gian và không gian của toàn bộ khung nhìn để trích suất vector đặc trưng từ dữ liệu. Phương pháp này mã hóa được các kiến thức về mặt không gian như các tư thế, các chuyển động theo thời gian. Và đây là các đặc trưng mạnh mẽ để nhận diện hành động.

Hai giải thuật đại diện cho phương pháp này là Motion History Image (MHI) và Motion Energy Image (MEI). Cả hai phương pháp đều trích xuất hành động trong video thành 1 ảnh tỉnh duy nhất.

\begin{itemize}
    \item MEI tạo ra một mặt nạ chuyển động (motion mask). Tại các vùng có chuyển động xảy ra, mặt nạ có giá trị 1 và ngược lại là giá trị 0. Từ đó, sự phân bố không gian của chuyển động được biểu diễn và vùng sáng cho thấy nơi cả hành động xảy ra.
    \item MHI tương tự như MEI, nhưng ngoài cho thấy được hành động diễn ra ở đâu thì MHI còn cho biết nó diễn ra như thế nào về mặt thời gian. Cường độ của mỗi pixel trên MHI thể hiện lịch sử chuyển động tại vị trí đó, trong đó các giá trị sáng hơn tương ứng với chuyển động gần đây hơn.
\end{itemize}

Khả năng trích suất đặc trưng của hai giải thuật trên là rất ấn tượng khi trích suất trên tập dữ liệu có góc nhìn cố định, và chỉ có chủ thể cần nhận diện hành động là di chuyển. Hai điều kiện trên rất khó xảy ra trong thức tế, vì vậy cần những phương pháp khác phù hợp hơn.

% TODO: 3DHOG 

\subsubsection{Phương pháp biểu diễn dữ liệu cục bộ}

Để khắc phục yếu điểm của phương pháp trích suất toàn cục, các phương pháp trích suất cục bộ đã ra đời, và hai đại diện nổi trội nhất cho phương pháp này là space-time interest points (STIP) và motion trajectory (MT).

Các phương pháp dựa trên STIP không chỉ trích xuất các đặc trưng về không gian mà còn có thêm thời gian. Nhờ đó phương pháp này được sử dụng rộng rãi trong bài toán nhận diện hành động. Nó cho phép trích xuất được những chuyển động quan trọng từ video để biểu diện hành động. Hầu hết các phương pháp dựa trên STIP đều kế thừa từ các phương pháp phát hiện vật thể cổ điển dùng cho ảnh tĩnh. Phổ biến nhất có thể kể đến giải thuật 3D-Harris, KLT, SIFT, HOG-HOF-MBH, PCA.

% Khó quá , Thức cứu Khôi nha <3









\subsection{Khảo sát các phương pháp học sâu}
\label{survey:method-deep-learning}

Trong những năm gần đây, việc ứng dụng học sâu vào thị giác máy tính đã nhận được nhiều sự quan tâm đáng kể. Nhiều phương pháp biểu diễn hành động dựa trên học sâu đã được đề xuất trong bài toán Nhận diện hành động trong video.

Các mô hình học sâu đó chủ yếu giải quyết đặc tính đặc biệt của dữ liệu đó dữ liệu dạng chuỗi các ảnh tĩnh. Và trong đó, các mô hình chủ yếu dựa trên 3 mô hình sau:


\textbf{3D convolutional networks:} mô hình này là sử mở rộng của 2D ConvNets vì chúng thu thêm thông tin về thời gian. Đây là một trong những phương pháp đầu tiên ứng dụng CNN để nhận diện hành động. Tuy nhiên phương pháp này tốn chi phí tính toán lớn, vì phải thực hiện 3D convolution trên nhiều frame liền kề nhau để trích suất cả thông tin về không gian và thời gian. Giải thuật này có hạn chế  rõ ràng là chúng thường xét các khoảng thời gian rất ngắn, thường khoảng 16 hay 32 khung hình để giảm chi phí tính toán.

\textbf{Two-stream convolutional networks:} Giống như tên gọi, đầu vào của mô hình gồm 2 thành phầm. Một là ảnh tĩnh chứa thông tin về không gian. Hai là optical flow được tính từ chuỗi các frame hình, chứa thông tin về thời gian. Hai đầu vào sẽ được đưa vào hai mạng CNN nhằm trích suất kiến thức về không thời gian. Kết quả của hai nhánh sẽ được tổng hợp lại để phân loại.

\textbf{Long short-term memory (LSTM):} Một cách tiếp cận khác để trích suất được thông tin về thời gian đó là thêm lớp họ RNN và CNN 2D, chẳng hạn như LSTM. Nhờ đó mô hình này có thể được khả năng hiểu dữ liệu không gian mạnh mẽ của CNN và trí nhớ dài hạn của LSTM.